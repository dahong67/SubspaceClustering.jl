var documenterSearchIndex = {"docs":
[{"location":"algs/kss/#K-subspaces-(KSS)","page":"K-subspaces","title":"K-subspaces (KSS)","text":"","category":"section"},{"location":"algs/kss/#Theory-/-Background","page":"K-subspaces","title":"Theory / Background","text":"todo: Todo\nWrite up mathematical background here","category":"section"},{"location":"algs/kss/#Syntax","page":"K-subspaces","title":"Syntax","text":"The following function runs KSS:\n\nThe output has the following type:","category":"section"},{"location":"algs/kss/#Examples","page":"K-subspaces","title":"Examples","text":"","category":"section"},{"location":"algs/kss/#KSS-with-equal-subspace-dimensions","page":"K-subspaces","title":"KSS with equal subspace dimensions","text":"todo: Todo\nWrite up example here","category":"section"},{"location":"algs/kss/#KSS-with-different-subspace-dimensions","page":"K-subspaces","title":"KSS with different subspace dimensions","text":"todo: Todo\nWrite up example here","category":"section"},{"location":"algs/kss/#KSS-with-reproducible-random-number-generation","page":"K-subspaces","title":"KSS with reproducible random number generation","text":"todo: Todo\nWrite up example here","category":"section"},{"location":"algs/kss/#KSS-with-custom-initialization","page":"K-subspaces","title":"KSS with custom initialization","text":"todo: Todo\nWrite up example here","category":"section"},{"location":"algs/kss/#KSS-with-custom-initialization-coming-from-clusters","page":"K-subspaces","title":"KSS with custom initialization coming from clusters","text":"todo: Todo\nWrite up example here where the subspace initialization is estimated from clusters","category":"section"},{"location":"algs/kss/#SubspaceClustering.kss-algs-kss","page":"K-subspaces","title":"SubspaceClustering.kss","text":"kss(X::AbstractMatrix{<:Real}, d::AbstractVector{<:Integer};\n    maxiters = 100,\n    rng = default_rng(),\n    Uinit = [randsubspace(rng, size(X, 1), di) for di in d])\n\nCluster the N data points in the DÃ—N data matrix X into K clusters via the K-subspaces (KSS) algorithm with corresponding subspace dimensions d[1],...,d[K]. Output is a KSSResult containing the resulting cluster assignments c[1],...,c[N], subspace basis matrices U[1],...,U[K], and metadata about the algorithm run.\n\nKSS seeks to cluster data points by their subspace by minimizing the following total cost\n\nsum_i=1^N  X i - Uci Uci X i _2^2\n\nwith respect to the cluster assignments c[1],...,c[N] and subspace basis matrices U[1],...,U[K].\n\nKeyword arguments\n\nmaxiters::Integer = 100: maximum number of iterations\nrng::AbstractRNG = default_rng(): random number generator   (used when reinitializing the subspace for an empty cluster)\nUinit::AbstractVector{<:AbstractMatrix{<:AbstractFloat}}   = [randsubspace(rng, size(X, 1), di) for di in d]:   vector of K initial subspace basis matrices to use   (each Uinit[k] should be DÃ—d[k])\n\nSee also KSSResult.\n\n\n\n\n\n","category":"function"},{"location":"algs/kss/#SubspaceClustering.KSSResult-algs-kss","page":"K-subspaces","title":"SubspaceClustering.KSSResult","text":"KSSResult{\n    TU<:AbstractVector{<:AbstractMatrix{<:AbstractFloat}},\n    Tc<:AbstractVector{<:Integer},\n    T<:Real}\n\nThe output of kss.\n\nFields\n\nU::TU: vector of subspace basis matrices U[1],...,U[K]\nc::Tc: vector of cluster assignments c[1],...,c[N]\niterations::Int: number of iterations performed\ntotalcost::T: final value of total cost function\ncounts::Vector{Int}: vector of cluster sizes counts[1],...,counts[K]\nconverged::Bool: final convergence status\n\n\n\n\n\n","category":"type"},{"location":"algs/tsc/#Thresholding-based-subspace-clustering-(TSC)","page":"Thresholding-based subspace clustering (TSC)","title":"Thresholding-based subspace clustering (TSC)","text":"","category":"section"},{"location":"algs/tsc/#Theory-/-Background","page":"Thresholding-based subspace clustering (TSC)","title":"Theory / Background","text":"todo: Todo\nWrite up mathematical background here","category":"section"},{"location":"algs/tsc/#Syntax","page":"Thresholding-based subspace clustering (TSC)","title":"Syntax","text":"The following function runs TSC:\n\nThe output has the following type:","category":"section"},{"location":"algs/tsc/#Examples","page":"Thresholding-based subspace clustering (TSC)","title":"Examples","text":"","category":"section"},{"location":"algs/tsc/#TSC-with-equal-subspace-dimensions","page":"Thresholding-based subspace clustering (TSC)","title":"TSC with equal subspace dimensions","text":"todo: Todo\nWrite up example here","category":"section"},{"location":"algs/tsc/#TSC-with-different-subspace-dimensions","page":"Thresholding-based subspace clustering (TSC)","title":"TSC with different subspace dimensions","text":"todo: Todo\nWrite up example here","category":"section"},{"location":"algs/tsc/#TSC-with-reproducible-random-number-generation","page":"Thresholding-based subspace clustering (TSC)","title":"TSC with reproducible random number generation","text":"todo: Todo\nWrite up example here","category":"section"},{"location":"algs/tsc/#SubspaceClustering.tsc-algs-tsc","page":"Thresholding-based subspace clustering (TSC)","title":"SubspaceClustering.tsc","text":"tsc(X::AbstractMatrix{<:Real}, K::Integer;\n    max_nz = max(4, cld(size(X, 2), max(1, K))),\n    max_chunksize = 1000,\n    rng = default_rng(),\n    kmeans_nruns = 10,\n    kmeans_opts = (;))\n\nCluster the N data points in the DÃ—N data matrix X into K clusters via the Thresholding-based Subspace Clustering (TSC) algorithm with affinity matrix formed using at most max_nz neighbors. Output is a TSCResult containing the resulting cluster assignments with the internally computed affinity matrix, embedding matrix, and K-means runs.\n\nTSC seeks to cluster data points by treating them as nodes of a weighted graph with weights given by a thresholded affinity matrix formed by thresholding the (transformed) absolute cosine similarities between every pair of points at max_nz neighbors then symmetrizing. Cluster assignments are then obtained via normalized spectral clustering of the graph.\n\nKeyword arguments\n\nmax_nz::Integer = max(4, cld(size(X, 2), max(1, K))): maximum number of neighbors\nmax_chunksize::Integer = 1000: chunk size used in tsc_affinity\nrng::AbstractRNG = default_rng(): random number generator used by K-means\nkmeans_nruns::Integer = 10: number of K-means runs to perform\nkmeans_opts = (;): additional options for kmeans\n\nSee also TSCResult, tsc_affinity, tsc_embedding.\n\n\n\n\n\n","category":"function"},{"location":"algs/tsc/#SubspaceClustering.TSCResult-algs-tsc","page":"Thresholding-based subspace clustering (TSC)","title":"SubspaceClustering.TSCResult","text":"\"     TSCResult{         TA<:AbstractMatrix{<:Real},         TE<:AbstractMatrix{<:Real},         TK<:KmeansResult,         Tc<:AbstractVector{<:Integer}}\n\nThe output of tsc.\n\nFields\n\naffinity::TA : NÃ—N TSC affinity matrix\nembedding::TE : KÃ—N TSC embedding matrix\nkmeans_runs::Vector{TK} : vector of outputs from batched K-means\nassignments::Tc : vector of final assignments\n\n\n\n\n\n","category":"type"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#SubspaceClustering.SubspaceClustering","page":"API","title":"SubspaceClustering.SubspaceClustering","text":"Subspace clustering module. Provides algorithms for clustering data points by subspace.\n\n\n\n\n\n","category":"module"},{"location":"api/#SubspaceClustering.KSSResult","page":"API","title":"SubspaceClustering.KSSResult","text":"KSSResult{\n    TU<:AbstractVector{<:AbstractMatrix{<:AbstractFloat}},\n    Tc<:AbstractVector{<:Integer},\n    T<:Real}\n\nThe output of kss.\n\nFields\n\nU::TU: vector of subspace basis matrices U[1],...,U[K]\nc::Tc: vector of cluster assignments c[1],...,c[N]\niterations::Int: number of iterations performed\ntotalcost::T: final value of total cost function\ncounts::Vector{Int}: vector of cluster sizes counts[1],...,counts[K]\nconverged::Bool: final convergence status\n\n\n\n\n\n","category":"type"},{"location":"api/#SubspaceClustering.TSCResult","page":"API","title":"SubspaceClustering.TSCResult","text":"\"     TSCResult{         TA<:AbstractMatrix{<:Real},         TE<:AbstractMatrix{<:Real},         TK<:KmeansResult,         Tc<:AbstractVector{<:Integer}}\n\nThe output of tsc.\n\nFields\n\naffinity::TA : NÃ—N TSC affinity matrix\nembedding::TE : KÃ—N TSC embedding matrix\nkmeans_runs::Vector{TK} : vector of outputs from batched K-means\nassignments::Tc : vector of final assignments\n\n\n\n\n\n","category":"type"},{"location":"api/#SubspaceClustering.kss-Tuple{AbstractMatrix{<:Real}, AbstractVector{<:Integer}}","page":"API","title":"SubspaceClustering.kss","text":"kss(X::AbstractMatrix{<:Real}, d::AbstractVector{<:Integer};\n    maxiters = 100,\n    rng = default_rng(),\n    Uinit = [randsubspace(rng, size(X, 1), di) for di in d])\n\nCluster the N data points in the DÃ—N data matrix X into K clusters via the K-subspaces (KSS) algorithm with corresponding subspace dimensions d[1],...,d[K]. Output is a KSSResult containing the resulting cluster assignments c[1],...,c[N], subspace basis matrices U[1],...,U[K], and metadata about the algorithm run.\n\nKSS seeks to cluster data points by their subspace by minimizing the following total cost\n\nsum_i=1^N  X i - Uci Uci X i _2^2\n\nwith respect to the cluster assignments c[1],...,c[N] and subspace basis matrices U[1],...,U[K].\n\nKeyword arguments\n\nmaxiters::Integer = 100: maximum number of iterations\nrng::AbstractRNG = default_rng(): random number generator   (used when reinitializing the subspace for an empty cluster)\nUinit::AbstractVector{<:AbstractMatrix{<:AbstractFloat}}   = [randsubspace(rng, size(X, 1), di) for di in d]:   vector of K initial subspace basis matrices to use   (each Uinit[k] should be DÃ—d[k])\n\nSee also KSSResult.\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.kss_assign_clusters!-Tuple{Any, Any, Any}","page":"API","title":"SubspaceClustering.kss_assign_clusters!","text":"kss_assign_clusters!(c, U, X)\n\nAssign the N data points in X to the K subspaces in U, update the vector of assignments c, and return this vector of assignments.\n\nSee also kss_assign_clusters, kss.\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.kss_assign_clusters-Tuple{Any, Any}","page":"API","title":"SubspaceClustering.kss_assign_clusters","text":"kss_assign_clusters(U, X)\n\nAssign the N data points in X to the K subspaces in U and return a vector of the assignments.\n\nSee also kss_assign_clusters!, kss.\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.kss_estimate_subspace-Tuple{Any, Any}","page":"API","title":"SubspaceClustering.kss_estimate_subspace","text":"kss_estimate_subspace(Xk, dk)\n\nReturn dk-dimensional subspace that best fits the data points in Xk.\n\nSee also kss.\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.randsubspace!-Tuple{Random.AbstractRNG, AbstractMatrix}","page":"API","title":"SubspaceClustering.randsubspace!","text":"randsubspace!([rng=default_rng()], U::AbstractMatrix)\n\nSet the DÃ—d matrix U to be the basis matrix of a randomly generated d-dimensional subspace of â„á´°.\n\nSee also randsubspace\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.randsubspace-Union{Tuple{T}, Tuple{Random.AbstractRNG, Type{T}, Integer, Integer}} where T<:AbstractFloat","page":"API","title":"SubspaceClustering.randsubspace","text":"randsubspace([rng=default_rng()], [T=Float64], D, d)\n\nGenerate a random d-dimensional subspace of â„á´° and return a basis matrix with element type T<:AbstractFloat.\n\nSee also randsubspace!\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.tsc-Tuple{AbstractMatrix{<:Real}, Integer}","page":"API","title":"SubspaceClustering.tsc","text":"tsc(X::AbstractMatrix{<:Real}, K::Integer;\n    max_nz = max(4, cld(size(X, 2), max(1, K))),\n    max_chunksize = 1000,\n    rng = default_rng(),\n    kmeans_nruns = 10,\n    kmeans_opts = (;))\n\nCluster the N data points in the DÃ—N data matrix X into K clusters via the Thresholding-based Subspace Clustering (TSC) algorithm with affinity matrix formed using at most max_nz neighbors. Output is a TSCResult containing the resulting cluster assignments with the internally computed affinity matrix, embedding matrix, and K-means runs.\n\nTSC seeks to cluster data points by treating them as nodes of a weighted graph with weights given by a thresholded affinity matrix formed by thresholding the (transformed) absolute cosine similarities between every pair of points at max_nz neighbors then symmetrizing. Cluster assignments are then obtained via normalized spectral clustering of the graph.\n\nKeyword arguments\n\nmax_nz::Integer = max(4, cld(size(X, 2), max(1, K))): maximum number of neighbors\nmax_chunksize::Integer = 1000: chunk size used in tsc_affinity\nrng::AbstractRNG = default_rng(): random number generator used by K-means\nkmeans_nruns::Integer = 10: number of K-means runs to perform\nkmeans_opts = (;): additional options for kmeans\n\nSee also TSCResult, tsc_affinity, tsc_embedding.\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.tsc_affinity-Tuple{Any}","page":"API","title":"SubspaceClustering.tsc_affinity","text":"tsc_affinity(X; max_nz = max(2, cld(size(X, 2), 4)), max_chunksize = 1000)\n\nCompute the sparse TSC affinity (i.e., adjacency) matrix for the N data points in X formed by thresholding their pairwise absolute cosine similarities at max_nz neighbors then symmetrizing.\n\nTo handle datasets with a large number of points N, the computation is performed over chunks of at most max_chunksize points at a time.\n\nSee also tsc.\n\n\n\n\n\n","category":"method"},{"location":"api/#SubspaceClustering.tsc_embedding-Tuple{Any, Any}","page":"API","title":"SubspaceClustering.tsc_embedding","text":"tsc_embedding(A, K)\n\nCompute the K-dimensional TSC embedding for the NÃ—N affinity matrix A, returning a KÃ—N matrix of embeddings.\n\n\n\n\n\n","category":"method"},{"location":"quickstart/#Quick-start-guide","page":"Quick start guide","title":"Quick start guide","text":"Let's install SubspaceClustering and run our first subspace clustering algorithm!","category":"section"},{"location":"quickstart/#Step-1:-Install-Julia","page":"Quick start guide","title":"Step 1: Install Julia","text":"Go to https://julialang.org/downloads and install the current stable release.\n\nTo check your installation, open up Julia and try a simple calculation like 1+1:\n\n1 + 1\n\nMore info: https://docs.julialang.org/en/v1/manual/getting-started/","category":"section"},{"location":"quickstart/#Step-2:-Install-SubspaceClustering","page":"Quick start guide","title":"Step 2: Install SubspaceClustering","text":"SubspaceClustering can be installed using Julia's excellent builtin package manager.\n\njulia> import Pkg; Pkg.add(\"SubspaceClustering\")\n\nThis downloads, installs, and precompiles SubspaceClustering (and all its dependencies). Don't worry if it takes a few minutes to complete.\n\ntip: Tip: Interactive package management with the Pkg REPL mode\nHere we used the functional API for the builtin package manager. Pkg also has a very nice interactive interface (called the Pkg REPL) that is built right into the Julia REPL!Learn more here: https://pkgdocs.julialang.org/v1/getting-started/\n\ntip: Tip: Pkg environments\nThe package manager has excellent support for creating separate installation environments. We strongly recommend using environments to create isolated and reproducible setups.Learn more here: https://pkgdocs.julialang.org/v1/environments/","category":"section"},{"location":"quickstart/#Step-3:-Run-SubspaceClustering","page":"Quick start guide","title":"Step 3: Run SubspaceClustering","text":"Let's create a synthetic dataset of N = 300 data points that are clustered around K = 3 one-dimensional subspaces of mathbbR^2. A simple way to do so is to:\n\nGenerate direction vectors bmu_1 dots bmu_K in mathbbR^2 for the clusters. Each bmu_j defines a corresponding one-dimensional subspace: operatornamespan(bmu_j) =  alpha bmu_j  alpha in mathbbR .\nGenerate cluster assignments c_1 dots c_N in 1 dots K for the data points.\nGenerate each data point bmx_i in mathbbR^2 by drawing a random point alpha_i bmu_c_i in mathbbR^2 from the corresponding cluster subspace and adding some small noise 005 bmvarepsilon_i in mathbbR^2:\n\nbmx_i = alpha_i bmu_c_i + 005 bmvarepsilon_i\nquad textwhere quad\nalpha_i sim mathcalN(01)\nquad textand quad\nbmvarepsilon_i sim mathcalN(0 bmI_2)\n\n\nThe following code does exactly that:\n\nimport Random   # hide\nRandom.seed!(5) # hide\nusing LinearAlgebra\nN, K = 300, 3;\nu = [normalize(randn(2)) for _ in 1:K]        # direction vectors\nc = rand(1:K, N)                            # cluster assignments\nx = [randn()*u[c[i]] + 0.05*randn(2) for i in 1:N]  # data points\n\nThe resulting data points look like this:\n\nfig  # hide\n\nNote how the data points cluster around three lines (i.e., three one-dimensional subspaces). This union-of-subspace structure (typically with higher-dimensional subspaces) is a common feature in modern data! Our goal is to cluster these data points by their corresponding subspace given only the data points (i.e., without knowing what the subspaces are). Subspace clustering algorithms allow us to do just that!\n\nTo cluster these data points, simply load the SubspaceClustering package and run one of the available algorithms. We'll use the K-subspaces (KSS) algorithm for this quick start guide.\n\nusing SubspaceClustering\nd = fill(1, K)  # vector of subspace dimensions\nX = stack(x)    # data matrix (columns are data points)\nresult = kss(X, d)\n\nThis returns a KSSResult containing the estimated subspace bases bmhatU_1 dots bmhatU_K, the cluster assignments hatc_1 dots hatc_N, and some metadata about the algorithm run.\n\nWe can extract each of these as follows:\n\nresult.U\nresult.c\n\nTo see how well kss clustered the data points, we plot these estimated subspaces results.U together with the data points colored by the estimated cluster assignments results.c (the uncolored data points seen by kss are shown on the left):\n\nfig  # hide\n\nKSS did a pretty good job of estimating the underlying subspaces and clustering the data points by corresponding subspace!\n\ntip: Congratulations!\nCongratulations! You have successfully installed SubspaceClustering and run the KSS subspace clustering algorithm!","category":"section"},{"location":"quickstart/#Next-steps","page":"Quick start guide","title":"Next steps","text":"Ready to learn more?\n\nTo learn about the KSS algorithm used here, check out the K-subspaces (KSS) page.\nExplore the other algorithms in this package! KSS is perhaps the simplest method to understand, but typically not the best performing. Check out the Algorithms Overview page to start.\n\nWant to understand the internals and possibly contribute? Check out the developer docs.","category":"section"},{"location":"#SubspaceClustering:-Cluster-data-points-by-subspace","page":"Home","title":"SubspaceClustering: Cluster data points by subspace","text":"Documentation for SubspaceClustering.\n\nðŸ‘‹ This package provides research code and work is ongoing. If you are interested in using it in your own research or in contributing to it, I'd love to hear from you and collaborate! Feel free to write: hong@udel.edu\n\nfig  # hide\n\nData points in many modern datasets lie not along a single low-dimensional subspace, but rather cluster around multiple low-dimensional subspaces (as illustrated above). This is sometimes called \"union-of-subspace\" structure since the data points lie near the union of these low-dimensional subspaces.\n\nSubspace clustering algorithms seek to cluster the data points by their corresponding subspace - without knowing the subspaces a priori!\n\nReady to start? Check out the quick start guide!","category":"section"},{"location":"devdocs/#Developer-Docs","page":"Developer Docs","title":"Developer Docs","text":"","category":"section"},{"location":"devdocs/#Live-preview-server-for-the-documentation","page":"Developer Docs","title":"Live preview server for the documentation","text":"Having a live preview can make it much easier to work on the documentation. We do this by running a local server that watches the files in docs/ and rebuilds the documentation whenever there are edits. The script docs/serve.jl takes care of setting that all up. Run it from the shell as follows:\n\n> julia docs/serve.jl   # from the package root folder\n\nYou should see a bunch of lines print out about the documentation build, concluding with a couple lines that look something like:\n\n[... lines about the documentation build ...]\nâœ“ LiveServer listening on http://localhost:8000/ ...\n  (use CTRL+C to shut down)\n\nOpening this link in a web browser will show a live preview of this documentation. Edit one of the documentation pages in docs/src and you should see your edits appear automatically!\n\nMinor Caveats:\n\nUpdates to docstrings are currently not automatically caught. To solve, simply shut down the server and relaunch.\nAdding a file to the documentation does not always register correctly. To solve, simply shut down the server and relaunch.\n\ntip: How does this all work?\nThe docs/serve.jl script does the following:Make sure the documentation packages (defined in docs/Project.toml) are all installed.\nBuild and serve the documentation using the servedocs function from LiveServer.jl.","category":"section"},{"location":"algs/main/#Algorithms-Overview","page":"Overview","title":"Algorithms Overview","text":"warning: Work-in-progress\nThis page of the docs is still a work-in-progress. Check back later!","category":"section"}]
}
